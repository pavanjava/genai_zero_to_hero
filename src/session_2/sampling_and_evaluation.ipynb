{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53727308-a2fc-48af-a4d5-52b1738f4d6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/bin/python\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/anaconda3/lib/python3.12/site-packages (2.9.0)\n",
      "Requirement already satisfied: torch-vision in /opt/anaconda3/lib/python3.12/site-packages (0.1.6.dev0)\n",
      "Requirement already satisfied: nltk in /opt/anaconda3/lib/python3.12/site-packages (3.9.1)\n",
      "Requirement already satisfied: bert_score in /opt/anaconda3/lib/python3.12/site-packages (0.3.13)\n",
      "Collecting accelerate\n",
      "  Downloading accelerate-1.11.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: click in /opt/anaconda3/lib/python3.12/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/lib/python3.12/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/anaconda3/lib/python3.12/site-packages (from nltk) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.12/site-packages (from nltk) (4.66.5)\n",
      "Requirement already satisfied: pandas>=1.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from bert_score) (2.2.2)\n",
      "Requirement already satisfied: transformers>=3.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from bert_score) (4.57.1)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (from bert_score) (1.26.4)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from bert_score) (2.32.3)\n",
      "Requirement already satisfied: matplotlib in /opt/anaconda3/lib/python3.12/site-packages (from bert_score) (3.9.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/anaconda3/lib/python3.12/site-packages (from bert_score) (24.1)\n",
      "Requirement already satisfied: psutil in /opt/anaconda3/lib/python3.12/site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in /opt/anaconda3/lib/python3.12/site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in /opt/anaconda3/lib/python3.12/site-packages (from accelerate) (0.36.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/anaconda3/lib/python3.12/site-packages (from accelerate) (0.6.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface_hub>=0.21.0->accelerate) (1.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=1.0.1->bert_score) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=1.0.1->bert_score) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=1.0.1->bert_score) (2023.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /opt/anaconda3/lib/python3.12/site-packages (from transformers>=3.0.0->bert_score) (0.22.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->bert_score) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->bert_score) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->bert_score) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->bert_score) (1.4.4)\n",
      "Requirement already satisfied: pillow>=8 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->bert_score) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->bert_score) (3.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->bert_score) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests->bert_score) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests->bert_score) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests->bert_score) (2025.8.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert_score) (1.16.0)\n",
      "Downloading accelerate-1.11.0-py3-none-any.whl (375 kB)\n",
      "Installing collected packages: accelerate\n",
      "Successfully installed accelerate-1.11.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in /opt/anaconda3/lib/python3.12/site-packages (7.8.1)\n",
      "Requirement already satisfied: comm>=0.1.3 in /opt/anaconda3/lib/python3.12/site-packages (from ipywidgets) (0.2.1)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=3.6.6 in /opt/anaconda3/lib/python3.12/site-packages (from ipywidgets) (3.6.6)\n",
      "Requirement already satisfied: ipython>=4.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from ipywidgets) (8.27.0)\n",
      "Requirement already satisfied: jupyterlab-widgets<3,>=1.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from ipywidgets) (1.0.0)\n",
      "Requirement already satisfied: decorator in /opt/anaconda3/lib/python3.12/site-packages (from ipython>=4.0.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/anaconda3/lib/python3.12/site-packages (from ipython>=4.0.0->ipywidgets) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/anaconda3/lib/python3.12/site-packages (from ipython>=4.0.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /opt/anaconda3/lib/python3.12/site-packages (from ipython>=4.0.0->ipywidgets) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from ipython>=4.0.0->ipywidgets) (2.15.1)\n",
      "Requirement already satisfied: stack-data in /opt/anaconda3/lib/python3.12/site-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/anaconda3/lib/python3.12/site-packages (from ipython>=4.0.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: notebook>=4.4.1 in /opt/anaconda3/lib/python3.12/site-packages (from widgetsnbextension~=3.6.6->ipywidgets) (7.4.5)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/anaconda3/lib/python3.12/site-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (2.14.1)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.27.1 in /opt/anaconda3/lib/python3.12/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (2.27.3)\n",
      "Requirement already satisfied: jupyterlab<4.5,>=4.4.5 in /opt/anaconda3/lib/python3.12/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (4.4.6)\n",
      "Requirement already satisfied: notebook-shim<0.3,>=0.2 in /opt/anaconda3/lib/python3.12/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: tornado>=6.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (6.4.1)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/anaconda3/lib/python3.12/site-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/anaconda3/lib/python3.12/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=4.0.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: executing in /opt/anaconda3/lib/python3.12/site-packages (from stack-data->ipython>=4.0.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: asttokens in /opt/anaconda3/lib/python3.12/site-packages (from stack-data->ipython>=4.0.0->ipywidgets) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in /opt/anaconda3/lib/python3.12/site-packages (from stack-data->ipython>=4.0.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: anyio>=3.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (4.2.0)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in /opt/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (21.3.0)\n",
      "Requirement already satisfied: jinja2>=3.0.3 in /opt/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (3.1.4)\n",
      "Requirement already satisfied: jupyter-client>=7.4.4 in /opt/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (8.6.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /opt/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (5.7.2)\n",
      "Requirement already satisfied: jupyter-events>=0.9.0 in /opt/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (0.10.0)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in /opt/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (0.4.4)\n",
      "Requirement already satisfied: nbconvert>=6.4.4 in /opt/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (7.16.4)\n",
      "Requirement already satisfied: nbformat>=5.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (5.10.4)\n",
      "Requirement already satisfied: overrides>=5.0 in /opt/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (7.4.0)\n",
      "Requirement already satisfied: packaging>=22.0 in /opt/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (24.1)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in /opt/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (0.14.1)\n",
      "Requirement already satisfied: pyzmq>=24 in /opt/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (25.1.2)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in /opt/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (1.8.2)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /opt/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (0.17.1)\n",
      "Requirement already satisfied: websocket-client>=1.7 in /opt/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (1.8.0)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from jupyterlab<4.5,>=4.4.5->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (2.0.4)\n",
      "Requirement already satisfied: httpx<1,>=0.25.0 in /opt/anaconda3/lib/python3.12/site-packages (from jupyterlab<4.5,>=4.4.5->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (0.27.0)\n",
      "Requirement already satisfied: ipykernel!=6.30.0,>=6.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from jupyterlab<4.5,>=4.4.5->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (6.30.1)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from jupyterlab<4.5,>=4.4.5->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (2.2.0)\n",
      "Requirement already satisfied: setuptools>=41.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from jupyterlab<4.5,>=4.4.5->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (75.1.0)\n",
      "Requirement already satisfied: babel>=2.10 in /opt/anaconda3/lib/python3.12/site-packages (from jupyterlab-server<3,>=2.27.1->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (2.11.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in /opt/anaconda3/lib/python3.12/site-packages (from jupyterlab-server<3,>=2.27.1->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (0.9.6)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in /opt/anaconda3/lib/python3.12/site-packages (from jupyterlab-server<3,>=2.27.1->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (4.23.0)\n",
      "Requirement already satisfied: requests>=2.31 in /opt/anaconda3/lib/python3.12/site-packages (from jupyterlab-server<3,>=2.27.1->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (2.32.3)\n",
      "Requirement already satisfied: six in /opt/anaconda3/lib/python3.12/site-packages (from asttokens->stack-data->ipython>=4.0.0->ipywidgets) (1.16.0)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/anaconda3/lib/python3.12/site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (3.7)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/anaconda3/lib/python3.12/site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (1.3.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /opt/anaconda3/lib/python3.12/site-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (21.2.0)\n",
      "Requirement already satisfied: pytz>=2015.7 in /opt/anaconda3/lib/python3.12/site-packages (from babel>=2.10->jupyterlab-server<3,>=2.27.1->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (2024.1)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/lib/python3.12/site-packages (from httpx<1,>=0.25.0->jupyterlab<4.5,>=4.4.5->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/lib/python3.12/site-packages (from httpx<1,>=0.25.0->jupyterlab<4.5,>=4.4.5->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.25.0->jupyterlab<4.5,>=4.4.5->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (0.14.0)\n",
      "Requirement already satisfied: appnope>=0.1.2 in /opt/anaconda3/lib/python3.12/site-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab<4.5,>=4.4.5->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (0.1.3)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /opt/anaconda3/lib/python3.12/site-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab<4.5,>=4.4.5->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (1.6.7)\n",
      "Requirement already satisfied: nest-asyncio>=1.4 in /opt/anaconda3/lib/python3.12/site-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab<4.5,>=4.4.5->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (1.6.0)\n",
      "Requirement already satisfied: psutil>=5.7 in /opt/anaconda3/lib/python3.12/site-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab<4.5,>=4.4.5->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (5.9.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2>=3.0.3->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (2.1.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/anaconda3/lib/python3.12/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/anaconda3/lib/python3.12/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/anaconda3/lib/python3.12/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (0.10.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.12/site-packages (from jupyter-client>=7.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (2.9.0.post0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from jupyter-core!=5.0.*,>=4.12->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (3.10.0)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in /opt/anaconda3/lib/python3.12/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (2.0.7)\n",
      "Requirement already satisfied: pyyaml>=5.3 in /opt/anaconda3/lib/python3.12/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (6.0.1)\n",
      "Requirement already satisfied: rfc3339-validator in /opt/anaconda3/lib/python3.12/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (0.1.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/anaconda3/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (4.12.3)\n",
      "Requirement already satisfied: bleach!=5.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (4.1.0)\n",
      "Requirement already satisfied: defusedxml in /opt/anaconda3/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /opt/anaconda3/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (0.1.2)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in /opt/anaconda3/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (2.0.4)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (0.8.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/anaconda3/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (1.5.0)\n",
      "Requirement already satisfied: tinycss2 in /opt/anaconda3/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (1.2.1)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in /opt/anaconda3/lib/python3.12/site-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (2.16.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (2.2.3)\n",
      "Requirement already satisfied: webencodings in /opt/anaconda3/lib/python3.12/site-packages (from bleach!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (0.5.1)\n",
      "Requirement already satisfied: fqdn in /opt/anaconda3/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (1.5.1)\n",
      "Requirement already satisfied: isoduration in /opt/anaconda3/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in /opt/anaconda3/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (2.1)\n",
      "Requirement already satisfied: uri-template in /opt/anaconda3/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=24.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (24.11.1)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (1.17.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/anaconda3/lib/python3.12/site-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (2.5)\n",
      "Requirement already satisfied: pycparser in /opt/anaconda3/lib/python3.12/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (2.21)\n",
      "Requirement already satisfied: arrow>=0.15.0 in /opt/anaconda3/lib/python3.12/site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (1.2.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabling notebook extension jupyter-js-widgets/extension...\n",
      "      - Validating: \u001b[32mOK\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: jupyter [-h] [--version] [--config-dir] [--data-dir] [--runtime-dir]\n",
      "               [--paths] [--json] [--debug]\n",
      "               [subcommand]\n",
      "\n",
      "Jupyter: Interactive Computing\n",
      "\n",
      "positional arguments:\n",
      "  subcommand     the subcommand to launch\n",
      "\n",
      "options:\n",
      "  -h, --help     show this help message and exit\n",
      "  --version      show the versions of core jupyter packages and exit\n",
      "  --config-dir   show Jupyter config dir\n",
      "  --data-dir     show Jupyter data dir\n",
      "  --runtime-dir  show Jupyter runtime dir\n",
      "  --paths        show all Jupyter paths. Add --json for machine-readable\n",
      "                 format.\n",
      "  --json         output paths as machine-readable json\n",
      "  --debug        output debug information about paths\n",
      "\n",
      "Available subcommands: bundlerextension console dejavu events execute kernel\n",
      "kernelspec migrate nbclassic nbconvert nbextension notebook qtconsole run\n",
      "server serverextension troubleshoot trust\n",
      "\n",
      "Jupyter command `jupyter-labextension` not found.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "!{sys.executable} -m pip install torch torch-vision nltk bert_score accelerate\n",
    "\n",
    "!{sys.executable} -m pip install ipywidgets\n",
    "!jupyter nbextension enable --py widgetsnbextension\n",
    "!jupyter labextension install @jupyter-widgets/jupyterlab-manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3ad07b6-d484-421e-9774-5bc58821f891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing /opt/homebrew/lib/python3.10/site-packages/widgetsnbextension/static -> jupyter-js-widgets\n",
      "Making directory: /opt/homebrew/opt/python@3.10/Frameworks/Python.framework/Versions/3.10/share/jupyter/nbextensions/jupyter-js-widgets/\n",
      "Copying: /opt/homebrew/lib/python3.10/site-packages/widgetsnbextension/static/extension.js.LICENSE.txt -> /opt/homebrew/opt/python@3.10/Frameworks/Python.framework/Versions/3.10/share/jupyter/nbextensions/jupyter-js-widgets/extension.js.LICENSE.txt\n",
      "Copying: /opt/homebrew/lib/python3.10/site-packages/widgetsnbextension/static/extension.js.map -> /opt/homebrew/opt/python@3.10/Frameworks/Python.framework/Versions/3.10/share/jupyter/nbextensions/jupyter-js-widgets/extension.js.map\n",
      "Copying: /opt/homebrew/lib/python3.10/site-packages/widgetsnbextension/static/extension.js -> /opt/homebrew/opt/python@3.10/Frameworks/Python.framework/Versions/3.10/share/jupyter/nbextensions/jupyter-js-widgets/extension.js\n",
      "- Validating: \u001b[32mOK\u001b[0m\n",
      "\n",
      "    To initialize this nbextension in the browser every time the notebook (or other app) loads:\n",
      "    \n",
      "          jupyter nbextension enable widgetsnbextension --py --sys-prefix\n",
      "    \n",
      "Enabling notebook extension jupyter-js-widgets/extension...\n",
      "      - Validating: \u001b[32mOK\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbextension install --py widgetsnbextension --sys-prefix\n",
    "!jupyter nbextension enable --py widgetsnbextension --sys-prefix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daeacf86-f598-4443-8196-d19db7a68a7b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "# Text Generation: Theory and Practice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816aaed4-ad91-42f7-8f06-3c58aaaa57b5",
   "metadata": {},
   "source": [
    "### 1. Decoding Strategies\n",
    "When language models generate text, they predict probability distributions over vocabulary at each step. Decoding strategies determine how we select the next token from these distributions.\n",
    "\n",
    "### 1.1 Greedy Decoding\n",
    "Selects the highest probability token at each step.\n",
    "- Pros: Fast, deterministic\n",
    "- Cons: Can miss better overall sequences, repetitive output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "441862ac-f80b-43cb-9b17-3830a58ed6a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected token ID: 414\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def greedy_decode(logits):\n",
    "    \"\"\"\n",
    "    logits: tensor of shape (vocab_size,) with unnormalized scores\n",
    "    \"\"\"\n",
    "    probs = F.softmax(logits, dim=-1)\n",
    "    next_token = torch.argmax(probs, dim=-1)\n",
    "    return next_token\n",
    "\n",
    "# Example\n",
    "vocab_size = 1000\n",
    "logits = torch.randn(vocab_size)\n",
    "token = greedy_decode(logits)\n",
    "print(f\"Selected token ID: {token.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c0d8586-903f-4d80-8942-afa6740f1086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low temp (0.5): 6\n",
      "High temp (2.0): 907\n"
     ]
    }
   ],
   "source": [
    "### 1.2 Sampling Methods\n",
    "### Random Sampling\n",
    "### Sample from the full probability distribution.\n",
    "\n",
    "def random_sampling(logits, temperature=1.0):\n",
    "    \"\"\"\n",
    "    temperature: controls randomness (higher = more random)\n",
    "    \"\"\"\n",
    "    probs = F.softmax(logits / temperature, dim=-1)\n",
    "    next_token = torch.multinomial(probs, num_samples=1)\n",
    "    return next_token\n",
    "\n",
    "# Example with different temperatures\n",
    "logits = torch.randn(1000)\n",
    "print(\"Low temp (0.5):\", random_sampling(logits, 0.5).item())\n",
    "print(\"High temp (2.0):\", random_sampling(logits, 2.0).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d266e163-3268-4ecf-a58f-859d3bf5f3bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-k sampled token: 306\n"
     ]
    }
   ],
   "source": [
    "# Top-k Sampling\n",
    "# Sample from only the k most likely tokens.\n",
    "\n",
    "def top_k_sampling(logits, k=50, temperature=1.0):\n",
    "    \"\"\"\n",
    "    k: number of top tokens to consider\n",
    "    \"\"\"\n",
    "    # Get top k logits and indices\n",
    "    top_k_logits, top_k_indices = torch.topk(logits, k)\n",
    "    \n",
    "    # Apply temperature and softmax\n",
    "    probs = F.softmax(top_k_logits / temperature, dim=-1)\n",
    "    \n",
    "    # Sample from top k\n",
    "    next_token_idx = torch.multinomial(probs, num_samples=1)\n",
    "    next_token = top_k_indices[next_token_idx]\n",
    "    \n",
    "    return next_token\n",
    "\n",
    "# Example\n",
    "logits = torch.randn(1000)\n",
    "token = top_k_sampling(logits, k=50)\n",
    "print(f\"Top-k sampled token: {token.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d49142a-bbc5-4452-9355-ea148ffc2aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-p sampled token: 581\n"
     ]
    }
   ],
   "source": [
    "# Top-p (Nucleus) Sampling\n",
    "# Sample from the smallest set of tokens whose cumulative probability exceeds p.\n",
    "\n",
    "def top_p_sampling(logits, p=0.9, temperature=1.0):\n",
    "    \"\"\"\n",
    "    p: cumulative probability threshold (0 < p <= 1)\n",
    "    \"\"\"\n",
    "    # Apply temperature\n",
    "    probs = F.softmax(logits / temperature, dim=-1)\n",
    "    \n",
    "    # Sort probabilities in descending order\n",
    "    sorted_probs, sorted_indices = torch.sort(probs, descending=True)\n",
    "    \n",
    "    # Calculate cumulative probabilities\n",
    "    cumsum_probs = torch.cumsum(sorted_probs, dim=-1)\n",
    "    \n",
    "    # Find cutoff index where cumsum exceeds p\n",
    "    mask = cumsum_probs <= p\n",
    "    mask[0] = True  # Always include the top token\n",
    "    \n",
    "    # Filter probabilities\n",
    "    filtered_probs = sorted_probs * mask\n",
    "    filtered_probs = filtered_probs / filtered_probs.sum()  # Renormalize\n",
    "    \n",
    "    # Sample\n",
    "    next_token_idx = torch.multinomial(filtered_probs, num_samples=1)\n",
    "    next_token = sorted_indices[next_token_idx]\n",
    "    \n",
    "    return next_token\n",
    "\n",
    "# Example\n",
    "logits = torch.randn(1000)\n",
    "token = top_p_sampling(logits, p=0.9)\n",
    "print(f\"Top-p sampled token: {token.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7aed1227-2d3f-4546-89b2-467912ecd8f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beam search result: [1, 746, 196, 305, 648, 151, 526, 996, 46, 226, 802]\n"
     ]
    }
   ],
   "source": [
    "# 1.3 Beam Search\n",
    "# Maintains k most probable sequences (beams) at each step.\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import List\n",
    "\n",
    "@dataclass\n",
    "class Beam:\n",
    "    tokens: List[int]\n",
    "    score: float\n",
    "\n",
    "def beam_search(model, start_token, max_length=20, beam_width=5, vocab_size=1000):\n",
    "    \"\"\"\n",
    "    Simplified beam search implementation\n",
    "    model: callable that takes token sequence and returns logits\n",
    "    \"\"\"\n",
    "    # Initialize with start token\n",
    "    beams = [Beam(tokens=[start_token], score=0.0)]\n",
    "    \n",
    "    for _ in range(max_length):\n",
    "        candidates = []\n",
    "        \n",
    "        for beam in beams:\n",
    "            # Get logits for next token (mock with random for demo)\n",
    "            logits = torch.randn(vocab_size)\n",
    "            log_probs = F.log_softmax(logits, dim=-1)\n",
    "            \n",
    "            # Get top k tokens\n",
    "            top_k_log_probs, top_k_tokens = torch.topk(log_probs, beam_width)\n",
    "            \n",
    "            # Create new beams\n",
    "            for log_prob, token in zip(top_k_log_probs, top_k_tokens):\n",
    "                new_beam = Beam(\n",
    "                    tokens=beam.tokens + [token.item()],\n",
    "                    score=beam.score + log_prob.item()\n",
    "                )\n",
    "                candidates.append(new_beam)\n",
    "        \n",
    "        # Keep top beam_width candidates\n",
    "        beams = sorted(candidates, key=lambda x: x.score, reverse=True)[:beam_width]\n",
    "    \n",
    "    return beams[0].tokens  # Return best sequence\n",
    "\n",
    "# Example usage\n",
    "result = beam_search(None, start_token=1, max_length=10, beam_width=3)\n",
    "print(f\"Beam search result: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c55979-aebf-4910-ad5d-d68335dac96b",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{array}{|l|l|l|l|l|}\n",
    "\\hline\n",
    "\\textbf{Strategy} & \\textbf{Quality} & \\textbf{Diversity} & \\textbf{Speed} & \\textbf{Use Case} \\\\\n",
    "\\hline\n",
    "\\text{Greedy} & \\text{Moderate} & \\text{Low} & \\text{Fast} & \\text{Factual tasks} \\\\\n",
    "\\hline\n",
    "\\text{Top-k} & \\text{Good} & \\text{High} & \\text{Moderate} & \\text{Creative writing} \\\\\n",
    "\\hline\n",
    "\\text{Top-p} & \\text{Good} & \\text{High} & \\text{Moderate} & \\text{General purpose} \\\\\n",
    "\\hline\n",
    "\\text{Beam} & \\text{High} & \\text{Low} & \\text{Slow} & \\text{Translation, summarization} \\\\\n",
    "\\hline\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a301195-e774-4d6e-bf6f-3b06e6c936f0",
   "metadata": {},
   "source": [
    "# Use Case-1: Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a5bf4f2-e6a3-409f-9889-80f1ad796e22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd309385ff474048a32e3dde4ecfe211",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d3066f7ad2049349eb36606dcf5b35c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19e46301c34440aabdf965bcca83cf85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44ad53fb3d5c4093bd53b54eda5d497e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6707ea68bbb9449da4cd8dcbf7d17bad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f9b8cf3c02c4232947c4983adedc69f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original length: 71\n",
      "Summary: Artificial intelligence has made remarkable progress in recent years. Large language models like GPT have demonstrated impressive abilities in understanding and generating human-like text. However, challenges remain in areas such as explainability, bias mitigation, and ensuring AI\n",
      "Summary length: 37\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Using Hugging Face transformers\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "\n",
    "text = \"\"\"\n",
    "Artificial intelligence has made remarkable progress in recent years, \n",
    "with breakthroughs in natural language processing, computer vision, and \n",
    "reinforcement learning. Large language models like GPT have demonstrated \n",
    "impressive abilities in understanding and generating human-like text. \n",
    "These advances have led to practical applications in healthcare, finance, \n",
    "education, and many other domains. However, challenges remain in areas \n",
    "such as explainability, bias mitigation, and ensuring AI systems are \n",
    "safe and aligned with human values.\n",
    "\"\"\"\n",
    "\n",
    "# Abstractive summarization with beam search\n",
    "summary = summarizer(\n",
    "    text, \n",
    "    max_length=50, \n",
    "    min_length=20, \n",
    "    do_sample=False,  # Use beam search\n",
    "    num_beams=4\n",
    ")\n",
    "\n",
    "print(\"Original length:\", len(text.split()))\n",
    "print(\"Summary:\", summary[0]['summary_text'])\n",
    "print(\"Summary length:\", len(summary[0]['summary_text'].split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1f1385-e426-4a0e-ac9e-77258f4f190e",
   "metadata": {},
   "source": [
    "### Key parameters for summarization:\n",
    "\n",
    "- Use beam search for more coherent summaries\n",
    "- Balance max_length and min_length\n",
    "- Higher num_beams (4-8) for better quality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d71a44-1b6b-4316-8ab1-8e3f3b473ddd",
   "metadata": {},
   "source": [
    "# Use Case-2: Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bbfd8a4-f6b2-4288-be53-d407120bb50f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greedy: The future of artificial intelligence will be shaped by the decisions we make today. As AI becomes more prevalent in our daily lives, it is important to consider how we can ensure that it is used ethically and responsibly.\n",
      "One way to do this is through\n",
      "\n",
      "Sampling: The future of artificial intelligence will be defined by the way people choose to use it. Some say AI is a powerful tool that can help humanity achieve great things, while others worry about its potential risks and unintended consequences.\n",
      "AI has already made significant strides in\n",
      "\n",
      "Beam: The future of artificial intelligence will be shaped by the ethical and social implications of the technology. As AI becomes more prevalent in our daily lives, it is important to consider the potential consequences of its development and use. This includes the impact on employment, privacy\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "# Load model\n",
    "model_name = \"Qwen/Qwen2.5-1.5B-Instruct\"  # Smaller model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "prompt = \"The future of artificial intelligence will\"\n",
    "\n",
    "# Encode input\n",
    "input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "\n",
    "# Different decoding strategies\n",
    "with torch.no_grad():\n",
    "    outputs_greedy = model.generate(\n",
    "        input_ids,\n",
    "        max_length=50,\n",
    "        do_sample=False  # Greedy\n",
    "    )\n",
    "with torch.no_grad():\n",
    "    outputs_sampling = model.generate(\n",
    "        input_ids,\n",
    "        max_length=50,\n",
    "        do_sample=True,\n",
    "        top_k=50,\n",
    "        top_p=0.95,\n",
    "        temperature=0.8\n",
    "    )\n",
    "with torch.no_grad():\n",
    "    outputs_beam = model.generate(\n",
    "        input_ids,\n",
    "        max_length=50,\n",
    "        num_beams=5,\n",
    "        early_stopping=True\n",
    "    )\n",
    "\n",
    "print(\"Greedy:\", tokenizer.decode(outputs_greedy[0], skip_special_tokens=True))\n",
    "print(\"\\nSampling:\", tokenizer.decode(outputs_sampling[0], skip_special_tokens=True))\n",
    "print(\"\\nBeam:\", tokenizer.decode(outputs_beam[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7176df4-c4a6-4722-af98-6e1c7459bafd",
   "metadata": {},
   "source": [
    "### Best practices:\n",
    "\n",
    "- Creative tasks: Use sampling (top-p=0.9, temperature=0.7-1.0)\n",
    "- Factual tasks: Use greedy or beam search\n",
    "- Balanced: Top-p with moderate temperature (0.7-0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e49476-983b-47ec-843b-f43369254e9a",
   "metadata": {},
   "source": [
    "## 3. Evaluation Metrics\n",
    "\n",
    "### 3.1 BLEU (Bilingual Evaluation Understudy)\n",
    "\n",
    "Measures n-gram overlap between generated and reference texts. Originally designed for machine translation.\n",
    "\n",
    "**Formula:**\n",
    "\n",
    "$$\\text{BLEU} = BP \\times \\exp\\left(\\sum_{n=1}^{N} w_n \\times \\log p_n\\right)$$\n",
    "\n",
    "**Where:**\n",
    "- $p_n$ = n-gram precision\n",
    "- $w_n$ = weights (usually 1/4 for 1-4 grams)\n",
    "- $BP$ = brevity penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "749f506e-0101-4641-b4c7-2e29a2aae760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.0000\n",
      "BLEU-1: 0.8333\n",
      "BLEU-2: 0.7071\n",
      "BLEU-4: 0.0000\n",
      "Corpus BLEU: 0.0000\n",
      "Smoothed BLEU: 0.2541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu, corpus_bleu\n",
    "from nltk.translate.bleu_score import SmoothingFunction\n",
    "\n",
    "# Single sentence example\n",
    "reference = [['the', 'cat', 'is', 'on', 'the', 'mat']]\n",
    "candidate = ['the', 'cat', 'sat', 'on', 'the', 'mat']\n",
    "\n",
    "# Calculate BLEU score\n",
    "bleu_score = sentence_bleu(reference, candidate)\n",
    "print(f\"BLEU score: {bleu_score:.4f}\")\n",
    "\n",
    "# With different n-gram weights\n",
    "bleu_1 = sentence_bleu(reference, candidate, weights=(1, 0, 0, 0))\n",
    "bleu_2 = sentence_bleu(reference, candidate, weights=(0.5, 0.5, 0, 0))\n",
    "bleu_4 = sentence_bleu(reference, candidate, weights=(0.25, 0.25, 0.25, 0.25))\n",
    "\n",
    "print(f\"BLEU-1: {bleu_1:.4f}\")\n",
    "print(f\"BLEU-2: {bleu_2:.4f}\")\n",
    "print(f\"BLEU-4: {bleu_4:.4f}\")\n",
    "\n",
    "# Corpus-level BLEU\n",
    "references = [\n",
    "    [['the', 'cat', 'is', 'on', 'the', 'mat']],\n",
    "    [['there', 'is', 'a', 'dog', 'in', 'the', 'park']]\n",
    "]\n",
    "candidates = [\n",
    "    ['the', 'cat', 'sat', 'on', 'the', 'mat'],\n",
    "    ['a', 'dog', 'is', 'in', 'the', 'park']\n",
    "]\n",
    "\n",
    "corpus_bleu_score = corpus_bleu(references, candidates)\n",
    "print(f\"Corpus BLEU: {corpus_bleu_score:.4f}\")\n",
    "\n",
    "# Using smoothing for short sentences\n",
    "smooth = SmoothingFunction()\n",
    "bleu_smooth = sentence_bleu(reference, candidate, \n",
    "                            smoothing_function=smooth.method1)\n",
    "print(f\"Smoothed BLEU: {bleu_smooth:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816fc739-66dd-437b-894a-29f0cdd441b9",
   "metadata": {},
   "source": [
    "### BLEU Characteristics:\n",
    "\n",
    "- Range: 0 to 1 (higher is better)\n",
    "- Pros: Fast, language-agnostic, correlates with human judgment\n",
    "- Cons: Doesn't capture semantics, sensitive to length, requires references"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7339bc4f-e81b-4551-83c6-6715aab3b6ae",
   "metadata": {},
   "source": [
    "### 3.2 BERTScore\n",
    "* Uses contextual embeddings from BERT to compute similarity between tokens.\n",
    "Components:\n",
    "\n",
    "- Precision: Matching of candidate tokens to reference\n",
    "- Recall: Coverage of reference by candidate\n",
    "- F1: Harmonic mean of precision and recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc5f55f2-0d87-4f54-86fb-9cd278e62a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "360f3ebac5e24b25a5f5f39d5d29871c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3205556e18b241968eceefaeba0cc252",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 1.47 seconds, 1.36 sentences/sec\n",
      "\n",
      "BERTScore Results:\n",
      "Pair 1:\n",
      "  Precision: 0.9688\n",
      "  Recall: 0.9679\n",
      "  F1: 0.9684\n",
      "Pair 2:\n",
      "  Precision: 0.9552\n",
      "  Recall: 0.9607\n",
      "  F1: 0.9579\n",
      "\n",
      "Average F1: 0.9211\n"
     ]
    }
   ],
   "source": [
    "from bert_score import score\n",
    "\n",
    "# Example texts\n",
    "references = [\n",
    "    \"The cat is sitting on the mat.\",\n",
    "    \"Dogs are playing in the park.\"\n",
    "]\n",
    "\n",
    "candidates = [\n",
    "    \"A cat sits on a mat.\",\n",
    "    \"The dogs play at the park.\"\n",
    "]\n",
    "\n",
    "# Calculate BERTScore\n",
    "P, R, F1 = score(candidates, references, lang=\"en\", verbose=True)\n",
    "\n",
    "print(\"\\nBERTScore Results:\")\n",
    "for i, (p, r, f1) in enumerate(zip(P, R, F1)):\n",
    "    print(f\"Pair {i+1}:\")\n",
    "    print(f\"  Precision: {p:.4f}\")\n",
    "    print(f\"  Recall: {r:.4f}\")\n",
    "    print(f\"  F1: {f1:.4f}\")\n",
    "\n",
    "# Using specific model\n",
    "P, R, F1 = score(candidates, references, \n",
    "                 model_type=\"microsoft/deberta-xlarge-mnli\")\n",
    "\n",
    "# Batch processing\n",
    "print(f\"\\nAverage F1: {F1.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea86c792-52d0-46fe-87e8-a5d302158ebf",
   "metadata": {},
   "source": [
    "### BERTScore Characteristics:\n",
    "\n",
    "- Range: Typically 0.5 to 1.0 (higher is better)\n",
    "- Pros: Captures semantic similarity, robust to paraphrasing\n",
    "- Cons: Slower than BLEU, requires GPU for efficiency, model-dependent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310c619f-68bb-472b-b28c-612b501bbe3e",
   "metadata": {},
   "source": [
    "## Metric Selection\n",
    "\n",
    "$$\n",
    "\\begin{array}{|l|l|l|}\n",
    "\\hline\n",
    "\\textbf{Task} & \\textbf{Primary Metric} & \\textbf{Secondary} \\\\\n",
    "\\hline\n",
    "\\text{Translation} & \\text{BLEU} & \\text{BERTScore} \\\\\n",
    "\\hline\n",
    "\\text{Summarization} & \\text{ROUGE} & \\text{BERTScore} \\\\\n",
    "\\hline\n",
    "\\text{Dialogue} & \\text{BERTScore} & \\text{Human eval} \\\\\n",
    "\\hline\n",
    "\\text{Paraphrase} & \\text{BERTScore} & \\text{BLEU} \\\\\n",
    "\\hline\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed5425b-acc9-4b56-8df2-f54428094893",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
