{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d92d96525b2c75ea",
   "metadata": {},
   "source": [
    "## LLM Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4eacb15e0317dce",
   "metadata": {},
   "source": [
    "- Temperature - In short, the lower the temperature, the more deterministic the results in the sense that the highest probable next token is always picked. Increasing temperature could lead to more randomness, which encourages more diverse or creative outputs. You are essentially increasing the weights of the other possible tokens. In terms of application, you might want to use a lower temperature value for tasks like fact-based QA to encourage more factual and concise responses. For poem generation or other creative tasks, it might be beneficial to increase the temperature value.\n",
    "\n",
    "\n",
    "- Top P - A sampling technique with temperature, called nucleus sampling, where you can control how deterministic the model is. If you are looking for exact and factual answers keep this low. If you are looking for more diverse responses, increase to a higher value. If you use Top P it means that only the tokens comprising the top_p probability mass are considered for responses, so a low top_p value selects the most confident responses. This means that a high top_p value will enable the model to look at more possible words, including less likely ones, leading to more diverse outputs.\n",
    "\n",
    "#### The general recommendation is to alter temperature or Top P but not both."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efea52ff53c8b2d",
   "metadata": {},
   "source": [
    "- Frequency Penalty - The frequency penalty applies a penalty on the next token proportional to how many times that token already appeared in the response and prompt. The higher the frequency penalty, the less likely a word will appear again. This setting reduces the repetition of words in the model's response by giving tokens that appear more a higher penalty.\n",
    "\n",
    "\n",
    "- Presence Penalty - The presence penalty also applies a penalty on repeated tokens but, unlike the frequency penalty, the penalty is the same for all repeated tokens. A token that appears twice and a token that appears 10 times are penalized the same. This setting prevents the model from repeating phrases too often in its response. If you want the model to generate diverse or creative text, you might want to use a higher presence penalty. Or, if you need the model to stay focused, try using a lower presence penalty.\n",
    "\n",
    "#### Similar to temperature and top_p, the general recommendation is to alter the frequency or presence penalty but not both."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1187b2c3ca248702",
   "metadata": {},
   "source": [
    "## Elements of a Prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f6d5b3d580e852",
   "metadata": {},
   "source": [
    "As we cover more and more examples and applications with prompt engineering, you will notice that certain elements make up a prompt.\n",
    "\n",
    "A prompt contains any of the following elements:\n",
    "\n",
    "Instruction - a specific task or instruction you want the model to perform\n",
    "\n",
    "Context - external information or additional context that can steer the model to better responses\n",
    "\n",
    "Input Data - the input or question that we are interested to find a response for\n",
    "\n",
    "Output Indicator - the type or format of the output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8abcf9757707a0e",
   "metadata": {},
   "source": [
    "### Start Simple\n",
    "\n",
    "Begin with straightforward prompts and incrementally add context to enhance results. For complex tasks, decompose them into simpler subtasks to avoid overwhelming the prompt design process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0991b67f7ab69d2",
   "metadata": {},
   "source": [
    "### The Instruction\n",
    "\n",
    "Use clear commands like \"Write,\" \"Classify,\" \"Summarize,\" or \"Translate\" to specify the desired task. Experiment with different instructions, keywords, and contexts to determine what works best for your specific use case. Placing instructions at the beginning of the prompt and using clear separators, such as \"###,\" can help delineate instructions from context."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14cca5ef965d9fb9",
   "metadata": {},
   "source": [
    "### Specificity\n",
    "\n",
    "Provide detailed and relevant instructions to guide the model effectively. While being specific is crucial, ensure that the details included are pertinent to the task. Including examples in the prompt can be particularly effective in achieving the desired output format. Be mindful of prompt length, as overly lengthy prompts may not yield better results. Continuous experimentation and iteration are essential to optimize prompts for your applications. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e259126586e823",
   "metadata": {},
   "source": [
    "### Avoid Impreciseness\n",
    "\n",
    "Ambiguity in prompts can lead to unintended outputs. Ensure that instructions are clear and unambiguous to guide the model toward the desired response."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524de1842b68362c",
   "metadata": {},
   "source": [
    "### To Do or Not to Do?\n",
    "\n",
    "When instructing the model, clearly state what actions it should perform and what it should avoid. Explicitly outlining do's and don'ts can help in steering the model's responses more effectively.\n",
    "\n",
    "By adhering to these guidelines, you can design prompts that effectively guide language models to produce accurate and relevant outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f9c7c20cd4a62a",
   "metadata": {},
   "source": [
    "## Examples of Prompts\n",
    "- Text Summarization\n",
    "- Information Extraction\n",
    "- Question Answering\n",
    "- Text Classification\n",
    "- Conversation\n",
    "- Code Generation\n",
    "- Reasoning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53982efd36dcdd38",
   "metadata": {},
   "source": [
    "reference: https://www.promptingguide.ai/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9000c8dfefe96706",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9763609ff37137a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3167140d363b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
